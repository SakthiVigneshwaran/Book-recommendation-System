{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbb0e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import requests\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from PIL import Image\n",
    "warnings.filterwarnings('ignore')\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4237fbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "books = pd.read_csv('C:/Users/Yusuf/Desktop/BookRecommendationSystem/Preprocessed_data.csv')\n",
    "books.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532fc3bf",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3204b9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = books.copy()\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df.drop(columns = ['Unnamed: 0','location','isbn',\n",
    "                   'img_s','img_m','city','age',\n",
    "                   'state','Language','country',\n",
    "                   'year_of_publication'],axis=1,inplace = True) #remove useless cols\n",
    "\n",
    "df.drop(index=df[df['Category'] == '9'].index, inplace=True) #remove 9 in category\n",
    "\n",
    "df.drop(index=df[df['rating'] == 0].index, inplace=True) #remove 0 in rating\n",
    "\n",
    "df['Category'] = df['Category'].apply(lambda x: re.sub('[\\W_]+',' ',x).strip())\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5261ec24",
   "metadata": {},
   "source": [
    "# Item-Based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe22a768",
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_based_recommender(book_title):\n",
    "    \n",
    "    book_title = str(book_title)\n",
    "    if book_title in df['book_title'].values:\n",
    "    \n",
    "        rating_counts = pd.DataFrame(df['book_title'].value_counts())\n",
    "        rare_books = rating_counts[rating_counts['book_title'] <= 180].index\n",
    "        common_books = df[~df['book_title'].isin(rare_books)]\n",
    "        \n",
    "        if book_title in rare_books:\n",
    "            \n",
    "            random = pd.Series(common_books['book_title'].unique()).sample(2).values\n",
    "            print('There are no recommendations for this book')\n",
    "            print('Try: \\n')\n",
    "            print('{}'.format(random[0]),'\\n')\n",
    "            print('{}'.format(random[1]),'\\n')\n",
    "        \n",
    "        else:\n",
    "            user_book_df = common_books.pivot_table(index=['user_id'],\n",
    "                                                    columns=['book_title'],\n",
    "                                                    values='rating')\n",
    "        \n",
    "            book = user_book_df[book_title]\n",
    "            recom_data = pd.DataFrame(user_book_df.corrwith(book). \\\n",
    "                                      sort_values(ascending=False)).reset_index(drop=False)\n",
    "            \n",
    "            if book_title in [book for book in recom_data['book_title']]:\n",
    "                recom_data = recom_data.drop(recom_data[recom_data['book_title'] == book_title].index[0])\n",
    "                \n",
    "            low_rating = []\n",
    "            for i in recom_data['book_title']:\n",
    "                if df[df['book_title'] == i]['rating'].mean() < 5:\n",
    "                    low_rating.append(i)\n",
    "                    \n",
    "            if recom_data.shape[0] - len(low_rating) > 5:\n",
    "                recom_data = recom_data[~recom_data['book_title'].isin(low_rating)]\n",
    "            \n",
    "            recom_data = recom_data[0:5]    \n",
    "            recom_data.columns = ['book_title','corr']\n",
    "            \n",
    "            fig, axs = plt.subplots(1, 5,figsize=(18,5))\n",
    "            fig.suptitle('You may also like these books', size = 22)\n",
    "            for i in range(len(recom_data['book_title'].tolist())):\n",
    "        \n",
    "                url = books.loc[books['book_title'] == recom_data['book_title'].tolist()[i],'img_l'][:1].values[0]\n",
    "                im = Image.open(requests.get(url, stream=True).raw)\n",
    "                axs[i].imshow(im)\n",
    "                axs[i].axis(\"off\")\n",
    "                axs[i].set_title('Rating: {}'.format(round(df[df['book_title'] == recom_data['book_title'].tolist()[i]]['rating'].mean(),1)),\n",
    "                             y=-0.18,\n",
    "                                 color=\"red\",\n",
    "                                 fontsize=18)\n",
    "                fig.show()\n",
    "    else:\n",
    "        print('Cant find book in dataset, please check spelling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0f5a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_based_recommender('Fahrenheit 451')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376d3fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_based_recommender('The Street Lawyer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3fad86",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_based_recommender('Divine Secrets of the Ya-Ya Sisterhood: A Novel')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a66478",
   "metadata": {},
   "source": [
    "# Content-Based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578d2022",
   "metadata": {},
   "source": [
    "Title, Author, Publisher, Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5720cbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_based_recommender(book_title):\n",
    "    \n",
    "    book_title = str(book_title)\n",
    "    if book_title in df['book_title'].values:\n",
    "        rating_counts = pd.DataFrame(df['book_title'].value_counts())\n",
    "        rare_books = rating_counts[rating_counts['book_title'] <= 100].index\n",
    "        common_books = df[~df['book_title'].isin(rare_books)]\n",
    "        \n",
    "        if book_title in rare_books:\n",
    "            \n",
    "            random = pd.Series(common_books['book_title'].unique()).sample(2).values\n",
    "            print('There are no recommendations for this book')\n",
    "            print('Try: \\n')\n",
    "            print('{}'.format(random[0]),'\\n')\n",
    "            print('{}'.format(random[1]),'\\n')\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            common_books = common_books.drop_duplicates(subset=['book_title'])\n",
    "            common_books.reset_index(inplace= True)\n",
    "            common_books['index'] = [i for i in range(common_books.shape[0])]\n",
    "            target_cols = ['book_title','book_author','publisher','Category']\n",
    "            common_books['combined_features'] = [' '.join(common_books[target_cols].iloc[i,].values) for i in range(common_books[target_cols].shape[0])]\n",
    "            cv = CountVectorizer()\n",
    "            count_matrix = cv.fit_transform(common_books['combined_features'])\n",
    "            cosine_sim = cosine_similarity(count_matrix)\n",
    "            index = common_books[common_books['book_title'] == book_title]['index'].values[0]\n",
    "            sim_books = list(enumerate(cosine_sim[index]))\n",
    "            sorted_sim_books = sorted(sim_books,key=lambda x:x[1],\n",
    "                                      reverse=True)[1:6]\n",
    "            \n",
    "            books = []\n",
    "            for i in range(len(sorted_sim_books)):\n",
    "                books.append(common_books[common_books['index'] == sorted_sim_books[i][0]]['book_title'].item())\n",
    "            \n",
    "            fig, axs = plt.subplots(1, 5,figsize=(18,5))\n",
    "            fig.suptitle('You may also like these books', size = 22)\n",
    "            for i in range(len(books)):\n",
    "        \n",
    "                url = common_books.loc[common_books['book_title'] == books[i],'img_l'][:1].values[0]\n",
    "                im = Image.open(requests.get(url, stream=True).raw)\n",
    "                axs[i].imshow(im)\n",
    "                axs[i].axis(\"off\")\n",
    "                axs[i].set_title('Rating: {}'.format(round(df[df['book_title'] == books[i]]['rating'].mean(),1)),\n",
    "                             y=-0.18,\n",
    "                                 color=\"red\",\n",
    "                                 fontsize=18)\n",
    "                fig.show()\n",
    "                     \n",
    "    else:\n",
    "        \n",
    "        print('Cant find book in dataset, please check spelling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a98f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_based_recommender('Animal Farm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e608fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_based_recommender('1st to Die: A Novel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f93c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_based_recommender('Harry Potter and the Order of the Phoenix (Book 5)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdf8581",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98123f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "babf1172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_based_recommender2(book_title):\n",
    "    \n",
    "    book_title = str(book_title)\n",
    "    if book_title in df['book_title'].values:\n",
    "        rating_counts = pd.DataFrame(df['book_title'].value_counts())\n",
    "        rare_books = rating_counts[rating_counts['book_title'] <= 100].index\n",
    "        common_books = df[~df['book_title'].isin(rare_books)]\n",
    "        \n",
    "        if book_title in rare_books:\n",
    "            \n",
    "            random = pd.Series(common_books['book_title'].unique()).sample(2).values\n",
    "            print('There are no recommendations for this book')\n",
    "            print('Try: \\n')\n",
    "            print('{}'.format(random[0]),'\\n')\n",
    "            print('{}'.format(random[1]),'\\n')\n",
    "        \n",
    "        else:\n",
    "            common_books = common_books.drop_duplicates(subset=['book_title'])\n",
    "            common_books.reset_index(inplace= True)\n",
    "            common_books['index'] = [i for i in range(common_books.shape[0])]\n",
    "            \n",
    "            summary_filtered = []\n",
    "            for i in common_books['Summary']:\n",
    "                \n",
    "                i = re.sub(\"[^a-zA-Z]\",\" \",i).lower()\n",
    "                i = nltk.word_tokenize(i)\n",
    "                i = [word for word in i if not word in set(stopwords.words(\"english\"))]\n",
    "                i = \" \".join(i)\n",
    "                summary_filtered.append(i)\n",
    "            \n",
    "            common_books['Summary'] = summary_filtered   \n",
    "            cv = CountVectorizer()\n",
    "            count_matrix = cv.fit_transform(common_books['Summary'])\n",
    "            cosine_sim = cosine_similarity(count_matrix)\n",
    "            index = common_books[common_books['book_title'] == book_title]['index'].values[0]\n",
    "            sim_books = list(enumerate(cosine_sim[index]))\n",
    "            sorted_sim_books = sorted(sim_books,key=lambda x:x[1],reverse=True)[1:6]\n",
    "            \n",
    "            books = []\n",
    "            for i in range(len(sorted_sim_books)):\n",
    "                books.append(common_books[common_books['index'] == sorted_sim_books[i][0]]['book_title'].item())\n",
    "            \n",
    "            fig, axs = plt.subplots(1, 5,figsize=(18,5))\n",
    "            fig.suptitle('You may also like these books', size = 22)\n",
    "            for i in range(len(books)):\n",
    "        \n",
    "                url = common_books.loc[common_books['book_title'] == books[i],'img_l'][:1].values[0]\n",
    "                im = Image.open(requests.get(url, stream=True).raw)\n",
    "                axs[i].imshow(im)\n",
    "                axs[i].axis(\"off\")\n",
    "                axs[i].set_title('Rating: {}'.format(round(df[df['book_title'] == books[i]]['rating'].mean(),1)),\n",
    "                             y=-0.18,\n",
    "                                 color=\"red\",\n",
    "                                 fontsize=18)\n",
    "                fig.show()\n",
    "                     \n",
    "    else:\n",
    "        \n",
    "        print('Cant find book in dataset, please check spelling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e530bb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_based_recommender2('To Kill a Mockingbird')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caeb1514",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_based_recommender2('A Walk to Remember')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a45f89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_based_recommender2('A Painted House')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690b897d",
   "metadata": {},
   "source": [
    "# Custom Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2e3e8652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_recommender(book_title):\n",
    "    \n",
    "    #ITEM-BASED\n",
    "    book_title = str(book_title)\n",
    "    if book_title in df['book_title'].values:\n",
    "    \n",
    "        rating_counts = pd.DataFrame(df['book_title'].value_counts())\n",
    "        rare_books = rating_counts[rating_counts['book_title'] <= 180].index\n",
    "        common_books = df[~df['book_title'].isin(rare_books)]\n",
    "        \n",
    "        if book_title in rare_books:\n",
    "            \n",
    "            random = pd.Series(common_books['book_title'].unique()).sample(2).values\n",
    "            print('There are no recommendations for this book')\n",
    "            print('Try: \\n')\n",
    "            print('{}'.format(random[0]),'\\n')\n",
    "            print('{}'.format(random[1]),'\\n')\n",
    "        \n",
    "        else:\n",
    "            user_book_df = common_books.pivot_table(index=['user_id'],\n",
    "                                                    columns=['book_title'], values='rating')\n",
    "        \n",
    "            book = user_book_df[book_title]  \n",
    "            recom_data = pd.DataFrame(user_book_df.corrwith(book). \\\n",
    "                                      sort_values(ascending=False)).reset_index(drop=False)\n",
    "            \n",
    "            if book_title in [book for book in recom_data['book_title']]:\n",
    "                recom_data = recom_data.drop(recom_data[recom_data['book_title'] == book_title].index[0])\n",
    "                \n",
    "            low_rating = []\n",
    "            for i in recom_data['book_title']:\n",
    "                if df[df['book_title'] == i]['rating'].mean() < 5:\n",
    "                    low_rating.append(i)\n",
    "                    \n",
    "            if recom_data.shape[0] - len(low_rating) > 5:\n",
    "                recom_data = recom_data[~recom_data['book_title'].isin(low_rating)]\n",
    "            \n",
    "            recom_data = recom_data[0:1]    \n",
    "            recom_data.columns = ['book_title','corr']\n",
    "            recommended_books = []\n",
    "            for i in recom_data['book_title']:\n",
    "                recommended_books.append(i)\n",
    "                \n",
    "            df_new = df[~df['book_title'].isin(recommended_books)]\n",
    "            \n",
    "            #CONTENT-BASED (Title, Author, Publisher, Category)\n",
    "            rating_counts = pd.DataFrame(df_new['book_title'].value_counts())\n",
    "        \n",
    "            rare_books = rating_counts[rating_counts['book_title'] <= 100].index\n",
    "    \n",
    "            common_books = df_new[~df_new['book_title'].isin(rare_books)]\n",
    "            common_books = common_books.drop_duplicates(subset=['book_title'])\n",
    "            common_books.reset_index(inplace= True)\n",
    "            common_books['index'] = [i for i in range(common_books.shape[0])]   \n",
    "            target_cols = ['book_title','book_author','publisher','Category']\n",
    "            common_books['combined_features'] = [' '.join(common_books[target_cols].iloc[i,].values) for i in range(common_books[target_cols].shape[0])]\n",
    "            cv = CountVectorizer()\n",
    "            count_matrix = cv.fit_transform(common_books['combined_features'])\n",
    "            cosine_sim = cosine_similarity(count_matrix)\n",
    "            index = common_books[common_books['book_title'] == book_title]['index'].values[0]\n",
    "            sim_books = list(enumerate(cosine_sim[index]))\n",
    "            sorted_sim_books = sorted(sim_books,key=lambda x:x[1],reverse=True)[1:2]\n",
    "            \n",
    "            books = []\n",
    "            for i in range(len(sorted_sim_books)):\n",
    "                books.append(common_books[common_books['index'] == sorted_sim_books[i][0]]['book_title'].item())\n",
    "                \n",
    "            for i in books:\n",
    "                recommended_books.append(i)\n",
    "            \n",
    "            df_new = df_new[~df_new['book_title'].isin(recommended_books)]\n",
    "            \n",
    "            #CONTENT-BASED (SUMMARY)\n",
    "            rating_counts = pd.DataFrame(df_new['book_title'].value_counts())\n",
    "            rare_books = rating_counts[rating_counts['book_title'] <= 100].index\n",
    "            common_books = df_new[~df_new['book_title'].isin(rare_books)]\n",
    "            \n",
    "            common_books = common_books.drop_duplicates(subset=['book_title'])\n",
    "            common_books.reset_index(inplace= True)\n",
    "            common_books['index'] = [i for i in range(common_books.shape[0])]\n",
    "            \n",
    "            summary_filtered = []\n",
    "            for i in common_books['Summary']:\n",
    "                \n",
    "                i = re.sub(\"[^a-zA-Z]\",\" \",i).lower()\n",
    "                i = nltk.word_tokenize(i)\n",
    "                i = [word for word in i if not word in set(stopwords.words(\"english\"))]\n",
    "                i = \" \".join(i)\n",
    "                summary_filtered.append(i)\n",
    "            \n",
    "            common_books['Summary'] = summary_filtered\n",
    "            cv = CountVectorizer()\n",
    "            count_matrix = cv.fit_transform(common_books['Summary'])\n",
    "            cosine_sim = cosine_similarity(count_matrix) \n",
    "            index = common_books[common_books['book_title'] == book_title]['index'].values[0]\n",
    "            sim_books = list(enumerate(cosine_sim[index]))\n",
    "            sorted_sim_books2 = sorted(sim_books,key=lambda x:x[1],reverse=True)[1:4]\n",
    "            sorted_sim_books = sorted_sim_books2[:2]\n",
    "            summary_books = []\n",
    "            for i in range(len(sorted_sim_books)):\n",
    "                summary_books.append(common_books[common_books['index'] == sorted_sim_books[i][0]]['book_title'].item())\n",
    "                \n",
    "            for i in summary_books:\n",
    "                recommended_books.append(i)\n",
    "                \n",
    "            df_new = df_new[~df_new['book_title'].isin(recommended_books)]\n",
    "            \n",
    "            #TOP RATED OF CATEGORY\n",
    "            category = common_books[common_books['book_title'] == book_title]['Category'].values[0]\n",
    "            top_rated = common_books[common_books['Category'] == category].groupby('book_title').agg({'rating':'mean'}).reset_index()\n",
    "            \n",
    "            if top_rated.shape[0] == 1:\n",
    "                recommended_books.append(common_books[common_books['index'] == sorted_sim_books2[2][0]]['book_title'].item())\n",
    "                \n",
    "            else:\n",
    "                top_rated.drop(top_rated[top_rated['book_title'] == book_title].index[0],inplace=True)\n",
    "                top_rated = top_rated.sort_values('rating',ascending=False).iloc[:1]['book_title'].values[0]\n",
    "                recommended_books.append(top_rated)\n",
    "                \n",
    "            fig, axs = plt.subplots(1, 5,figsize=(18,5))\n",
    "            fig.suptitle('You may also like these books', size = 22)\n",
    "            for i in range(len(recommended_books)):\n",
    "        \n",
    "                url = df.loc[df['book_title'] == recommended_books[i],'img_l'][:1].values[0]\n",
    "                im = Image.open(requests.get(url, stream=True).raw)\n",
    "                axs[i].imshow(im)\n",
    "                axs[i].axis(\"off\")\n",
    "                axs[i].set_title('Rating: {}'.format(round(df[df['book_title'] == recommended_books[i]]['rating'].mean(),1)),\n",
    "                             y=-0.18,\n",
    "                                 color=\"red\",\n",
    "                                 fontsize=18)\n",
    "                fig.show()     \n",
    "\n",
    "    else:\n",
    "        print('Cant find book in dataset, please check spelling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869f3d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_recommender('The Summons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a35db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_recommender('Snow Falling on Cedars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cea617b",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_recommender(\"Tuesdays with Morrie: An Old Man, a Young Man, and Life's Greatest Lesson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21362beb",
   "metadata": {},
   "source": [
    "# Comparison of All Recommenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3d449f",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_based_recommender('Harry Potter and the Order of the Phoenix (Book 5)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3120ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_based_recommender('Harry Potter and the Order of the Phoenix (Book 5)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b981bf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_based_recommender2('Harry Potter and the Order of the Phoenix (Book 5)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d149b1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_recommender('Harry Potter and the Order of the Phoenix (Book 5)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d90cba",
   "metadata": {},
   "source": [
    "Let's try another book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e5ce78",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_based_recommender('Girl with a Pearl Earring')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba7276f",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_based_recommender('Girl with a Pearl Earring')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fc0c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_based_recommender2('Girl with a Pearl Earring')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b1c2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_recommender('Girl with a Pearl Earring')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
